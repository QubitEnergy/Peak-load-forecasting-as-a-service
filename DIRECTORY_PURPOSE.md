# Directory Purpose Guide

## What Each Directory Is For

### ‚úÖ src/ (NEW - Use This!)
**Purpose**: Production-ready modular code
- `src/data_collectors/` - API clients (replaces old datek.py, energinet*.py)
- `src/data_processors/` - Data preprocessing (replaces old data_wrangling*.py)
- `src/models/` - ML models (replaces old power_prediction_system.py)
- `src/utils/` - Utilities and config

**Status**: ‚úÖ Use this code!

---

### ‚úÖ Datek_sensor_data/ (KEEP - Has Your Data!)
**Purpose**: Contains your collected Datek sensor data
- ‚úÖ **Keep**: All CSV files (your data!)
  - `energy_and_temperature.csv` - Ready to use for modeling
  - `all_minute_data.csv` - Raw minute-level data
  - `processed_minute_data_datek_API.csv` - Processed data
- ‚úÖ **Keep**: Configuration/data files
- ‚ö†Ô∏è Can organize later: PNG plots (generated outputs, 50+ files)

**Note**: These are **data files**, not code. They stay here.

---

### ‚úÖ Energinet/ (KEEP - Has Your Data!)
**Purpose**: Contains your Energinet API data
- ‚úÖ **Keep**: All CSV files (your data!)
  - `units.csv` - Meter configuration (still useful)
  - `*.csv` - Your Energinet energy data
- ‚ö†Ô∏è Can move: PDFs ‚Üí `docs/references/`

**Note**: These are **data files**, not code. They stay here.

---

### ‚úÖ Model_development/ (KEEP - Has Your Data & Research!)
**Purpose**: Contains processed data and research notebooks
- ‚úÖ **Keep**: CSV files
  - `energy_and_temperature.csv` - Ready to use for modeling
  - `energy_and_temperature_minute_data.csv` - Minute-level data
- ‚úÖ **Keep**: Jupyter notebooks (your research work)
  - `PoC_v2.ipynb`
  - `power_peak_forecasting_PoC.ipynb`
- ‚ö†Ô∏è Can move: PDFs ‚Üí `docs/references/`

**Note**: Contains your **processed data and research artifacts**.

---

### üì¶ archive/old_code/ (Reference Only)
**Purpose**: Old redundant Python scripts (for reference)
- ‚ùå **Don't use**: These are old, buggy versions
- ‚úÖ **Reference only**: If you need to see how something was done before

**Contains**:
- Old `datek.py`, `energinet*.py` scripts (replaced by `src/data_collectors/`)
- Old `data_wrangling*.py` scripts (replaced by `src/data_processors/`)
- Old `power_prediction_system.py` (replaced by `src/models/peak_predictor.py`)

---

### üìö notebooks/exploration/ (Analysis Scripts)
**Purpose**: One-off analysis and exploration scripts
- Moved here from old directories
- For exploration, not production code

---

## Data Flow: Old vs New

### How Data Was Processed Before:
```
1. datek.py (old script) 
   ‚Üí Collected data 
   ‚Üí Saved to Datek_sensor_data/all_minute_data.csv

2. data_wrangling.py (old script)
   ‚Üí Read all_minute_data.csv
   ‚Üí Processed it
   ‚Üí Saved to energy_and_temperature.csv

3. power_prediction_system.py (old script)
   ‚Üí Read energy_and_temperature.csv
   ‚Üí Trained model (with bugs!)
```

### How Data Is Processed Now:
```
1. src/data_collectors/stromme_client.py (new code)
   ‚Üí Collect data (same functionality, better code)
   ‚Üí Save to data/raw/ (or wherever you want)

2. src/data_processors/preprocessor.py (new code)
   ‚Üí Process raw data (same functionality, unified)
   ‚Üí Save to data/processed/

3. src/models/peak_predictor.py (new code - FIXED!)
   ‚Üí Read processed data
   ‚Üí Train model (bugs fixed!)
```

### BUT - You Can Skip Steps 1-2!

**Since you already have `energy_and_temperature.csv`, you can go straight to step 3:**

```python
# Use your existing processed data
df = pd.read_csv("Datek_sensor_data/energy_and_temperature.csv")
# OR
df = pd.read_csv("Model_development/energy_and_temperature.csv")

# Use new code to train
from src.models import PowerPeakPredictor
predictor = PowerPeakPredictor()
predictor.fit(df, meter_id='KGdRbnJc')
```

## What Should You Do?

### ‚úÖ Keep As-Is (Recommended):
- `Datek_sensor_data/` - Your data files
- `Energinet/` - Your data files  
- `Model_development/` - Your data and notebooks

### ‚úÖ Use New Code:
- `src/` - All new modules

### ‚ùå Don't Use:
- `archive/old_code/` - Old buggy scripts

### ‚ö†Ô∏è Optional Organization (Later):
You could organize data files into `data/` directories, but it's not necessary:
- Move CSVs to `data/processed/` or `data/raw/`
- Move PDFs to `docs/references/`
- Move notebooks to `notebooks/poc/`

**But this is optional!** Current structure works fine.

## Summary

| Directory | Purpose | Keep? | Contains |
|-----------|---------|-------|----------|
| `src/` | New modular code | ‚úÖ Use | Python modules |
| `Datek_sensor_data/` | Your sensor data | ‚úÖ Keep | CSV files, plots |
| `Energinet/` | Your Energinet data | ‚úÖ Keep | CSV files, configs |
| `Model_development/` | Processed data & research | ‚úÖ Keep | CSVs, notebooks, PDFs |
| `archive/old_code/` | Old scripts | ‚ùå Reference only | Old Python files |

**The key point**: Data files stayed where they are. Only Python scripts were moved/consolidated.

